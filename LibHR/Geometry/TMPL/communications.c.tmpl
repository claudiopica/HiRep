/***************************************************************************\
* Copyright (c) 2023, Sofie Martins                                         *   
* All rights reserved.                                                      * 
\***************************************************************************/

#include <string.h>
#include "geometry.h"
#include "Utils/generics.h"

#if !defined _FIELD_NAME
#error Missing _FIELD_NAME in communications.c
#endif
#if !defined _FIELD_TYPE
#error Missing _FIELD_TYPE in communications.c
#endif
#if !defined _SITE_TYPE
#error Missing _SITE_TYPE in communications.c
#endif
#if !defined _FIELD_DIM
#error Missing _FIELD_DIM in communications.c
#endif
#if !defined _GEOM_TYPE
#error Missing _GEOM_TYPE in communications.c
#endif
#if !defined _MPI_REAL
#error Missing _MPI_REAL in communications.c
#endif
#if !defined _REAL
#error Missing _REAL in communications.c
#endif

#define _DECLARE(_name, _args) void _F_NAME(_name,_FIELD_NAME) _args
#define _CONCAT_GPU(_name,_suffix) _name ## _suffix ## _gpu
#define _GPU_F_NAME(_name,_suffix) _CONCAT_GPU(_name,_suffix)
#define _GPU_DECLARE(_name, _args) void _GPU_F_NAME(_name,_FIELD_NAME) _args

#define _COMM_TYPE_FOR(_comm_type) \
        for (int _comm_type = CPU_COMM; _comm_type <= GPU_COMM; ++_comm_type)

#define _BUFFER_FOR(_comm_type, _i) \
        if (f->comm_type & _comm_type) for (int _i = 0; _i < _NUMBER_OF_BUFFERS(_GEOM_TYPE); ++_i)

// Need to send the rounded up buffer length only for the GPU
#define round_up_buflen(_val, _comm_type) (_comm_type == GPU_COMM ? ((((_val-1 )/ THREADSIZE) + 1) * THREADSIZE) : _val )

#if defined(WITH_NEW_GEOMETRY) && defined(WITH_MPI)
static void *_F_NAME(sendrecv_guard_,_FIELD_NAME)=NULL;
#endif

_DECLARE(sync_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    #ifdef WITH_NEW_GEOMETRY
    sync_field(f->type, _FIELD_DIM*sizeof(*f->ptr), _IS_SPINOR_LIKE, f->ptr, f->sendbuf_ptr);
    #else
    geometry_descriptor *type = f->type;
    for (int i = 0; i < _NUMBER_OF_COPIES(_GEOM_TYPE); ++i) {
        _SITE_TYPE *target = _DFIELD_AT(f, type->copy_to[i], 0, _FIELD_DIM);
        _SITE_TYPE *source = _DFIELD_AT(f, type->copy_from[i], 0, _FIELD_DIM);
        //_SITE_TYPE *target = f->ptr + _FIELD_DIM * type->copy_to[i];
        //_SITE_TYPE *source = f->ptr + _FIELD_DIM * type->copy_from[i];
        size_t mem_size = _FIELD_DIM * type->copy_len[i] * sizeof(_SITE_TYPE);
        memcpy(target, source, mem_size);
    }
    #endif 
    #endif
}

_GPU_DECLARE(sync_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    #ifdef WITH_GPU
    box_t *L = geometryBoxes->next;
    int i = 0;
    geometry_descriptor *type = f->type;

    int nbuffers = _NUMBER_OF_BUFFERS(_GEOM_TYPE);
    if (f->type==&glattice) nbuffers /= 2;
    while (L && i < nbuffers)
    {
        _F_NAME(sync_box_to_buffer_gpu_,_FIELD_NAME)(f->type, L->sendBox, f, f->sendbuf_gpu_ptr);
        L=L->next; i++;
    }  
    #endif 
    #endif              
}

_DECLARE(start_sendrecv_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    const int mpi_chunks_per_site = sizeof(_SITE_TYPE)/sizeof(_REAL);

    #ifdef WITH_NEW_GEOMETRY
    if (_F_NAME(sendrecv_guard_,_FIELD_NAME)!=NULL) {
        error(1, 1, __func__, "More simultaneous communication attempted. Exiting...\n");
    }
    _F_NAME(sendrecv_guard_,_FIELD_NAME) = (void*)f->comm_req;
    #endif

    _REAL *recv_buffer;
    _REAL *send_buffer;
    _COMM_TYPE_FOR(comm_type) {
        if (f->comm_type & comm_type) { _F_NAME(complete_sendrecv_,_FIELD_NAME) (f); }
        _BUFFER_FOR(comm_type, i) {
            if (comm_type & CPU_COMM) {
                #ifndef WITH_NEW_GEOMETRY
                int master_shift = type->master_shift;
                #else
                int master_shift = 0;
                #endif
                _F_NAME(sync_,_FIELD_NAME)(f);
                recv_buffer = (_REAL*)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
                send_buffer = (_REAL*)(_DFIELD_AT_PTR(f->sendbuf_ptr, f->type->sbuf_start[i], 0, master_shift, _FIELD_DIM));
            } else if (comm_type & GPU_COMM) {
                #ifdef WITH_GPU
                _GPU_F_NAME(sync_,_FIELD_NAME) (f);
                recv_buffer = (_REAL*)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));
                send_buffer = (_REAL*)(_DFIELD_AT_PTR(f->sendbuf_gpu_ptr, f->type->sbuf_start[i], 0, 0, _FIELD_DIM));
                #endif 
            }

            /* Data Destination Parameters */
            int recv_proc = f->type->rbuf_from_proc[i];
            int number_of_sites = round_up_buflen((f->type->rbuf_len[i]), comm_type);
            size_t recv_size_in_dbl = (_FIELD_DIM)*number_of_sites*mpi_chunks_per_site;

            /* Data Origin Parameters */
            int send_proc = f->type->sbuf_to_proc[i];
            number_of_sites = round_up_buflen((f->type->sbuf_len[i]), comm_type);
            size_t send_size_in_dbl = (_FIELD_DIM)*number_of_sites*mpi_chunks_per_site;

            /* Communications */
            MPI_Irecv(recv_buffer, recv_size_in_dbl, _MPI_REAL, recv_proc, i, cart_comm, &(f->comm_req[2*i+1]));
            MPI_Isend(send_buffer, send_size_in_dbl, _MPI_REAL, send_proc, i, cart_comm, &(f->comm_req[2*i]));
        }
    }   
    #endif       
}

_DECLARE(complete_sendrecv_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    int nreq = 2 * _NUMBER_OF_BUFFERS(_GEOM_TYPE);
    #ifdef WITH_NEW_GEOMETRY
        _F_NAME(sendrecv_guard_,_FIELD_NAME) = NULL;
    #endif
    if (nreq > 0) 
    { 
        MPI_Status status[nreq];
        MPI_Waitall(nreq, f->comm_req, status);
    }
    #endif
}

_DECLARE(fill_buffers_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    _COMM_TYPE_FOR(comm_type) {
        _BUFFER_FOR(comm_type, i) {
            int chunks_per_site = sizeof(_SITE_TYPE)/sizeof(_REAL);
            int number_of_sites = f->type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM*number_of_sites*chunks_per_site;

            _REAL* random_array = (_REAL*)malloc(buffer_length*sizeof(_REAL));

            if (comm_type & CPU_COMM) {
                _REAL* buffer = (_REAL*)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
                _F_NAME(random_,_REAL)(random_array, buffer_length);
                memcpy(buffer, random_array, buffer_length*sizeof(_REAL));
            } else if (comm_type & GPU_COMM) {
                #ifdef WITH_GPU
                _REAL* buffer = (_REAL*)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));
                _F_NAME(random_,_REAL)(random_array, buffer_length);
                cudaMemcpy(buffer, random_array, buffer_length*sizeof(_REAL), cudaMemcpyHostToDevice);
                #endif
            }
        }
    }
    #endif
}

_DECLARE(fill_buffers_with_zeroes_,(_FIELD_TYPE *f)) {
    #ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    _COMM_TYPE_FOR(comm_type) {
        _BUFFER_FOR(comm_type, i) {
            int chunks_per_site = sizeof(_SITE_TYPE)/sizeof(_REAL);
            int number_of_sites = f->type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM*number_of_sites*chunks_per_site;

            _REAL* zero_array = (_REAL*)malloc(buffer_length*sizeof(_REAL));

            if (comm_type & CPU_COMM) {
                _REAL* buffer = (_REAL*)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
                _F_NAME(zeroes_,_REAL)(zero_array, buffer_length);
                memcpy(buffer, zero_array, buffer_length*sizeof(_REAL));
            } else if (comm_type & GPU_COMM) {
                #ifdef WITH_GPU
                _REAL* buffer = (_REAL*)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));   
                _F_NAME(zeroes_,_REAL)(zero_array, buffer_length);
                cudaMemcpy(buffer, zero_array, buffer_length*sizeof(_REAL), cudaMemcpyHostToDevice);
                #endif
            }
        }
    }
    #endif   
}

#undef _FIELD_NAME
#undef _FIELD_TYPE
#undef _SITE_TYPE
#undef _FIELD_DIM
#undef _MPI_REAL
#undef _REAL
#undef round_up_buflen
