/***************************************************************************\
* Copyright (c) 2023, Sofie Martins, Claudio Pica                           *   
* All rights reserved.                                                      * 
\***************************************************************************/

#include <string.h>
#include "geometry.h"
#include "Utils/generics.h"

#if !defined _FIELD_NAME
#error Missing _FIELD_NAME in communications.c
#endif
#if !defined _FIELD_TYPE
#error Missing _FIELD_TYPE in communications.c
#endif
#if !defined _SITE_TYPE
#error Missing _SITE_TYPE in communications.c
#endif
#if !defined _FIELD_DIM
#error Missing _FIELD_DIM in communications.c
#endif
#if !defined _GEOM_TYPE
#error Missing _GEOM_TYPE in communications.c
#endif
#if !defined _MPI_REAL
#error Missing _MPI_REAL in communications.c
#endif
#if !defined _REAL
#error Missing _REAL in communications.c
#endif

#define _DECLARE(_name, _args) _FUNC(void, _name, _FIELD_NAME, _args)
#define _GPU_DECLARE(_name, _args) _GPU_FUNC(void, _name, _FIELD_NAME, _args)

#define _BUFFER_FOR(_i) for (int _i = 0; _i < _NUMBER_OF_BUFFERS(type, _GEOM_TYPE); ++_i)

// Need to send the rounded up buffer length only for the GPU
#define roundUp(_val, _mod) ((((_val - 1) / (_mod)) + 1) * (_mod))

#if defined(WITH_NEW_GEOMETRY) && defined(WITH_MPI)
static void *_F_NAME(sendrecv_guard_, _FIELD_NAME) = NULL;
#endif

_DECLARE(sync_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
#ifdef WITH_NEW_GEOMETRY
    sync_field(f->type, _FIELD_DIM * sizeof(*f->ptr), _IS_SPINOR_LIKE, f->ptr, f->sendbuf_ptr);
#else
    geometry_descriptor *type = f->type;
    for (int i = 0; i < _NUMBER_OF_COPIES(type, _GEOM_TYPE); ++i) {
        _SITE_TYPE *target = _DFIELD_AT(f, type->copy_to[i], 0, _FIELD_DIM);
        _SITE_TYPE *source = _DFIELD_AT(f, type->copy_from[i], 0, _FIELD_DIM);
        size_t mem_size = _FIELD_DIM * type->copy_len[i] * sizeof(_SITE_TYPE);
        memcpy(target, source, mem_size);
    }
#endif
#endif
}

_GPU_DECLARE(sync_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
#ifdef WITH_GPU
    box_t *L = geometryBoxes->next;
    int i = 0;
    geometry_descriptor *type = f->type;

    int nbuffers = _NUMBER_OF_BUFFERS(type, _GEOM_TYPE);
    if (f->type == &glattice) { nbuffers /= 2; }
    while (L && i < nbuffers) {
        _F_NAME(sync_box_to_buffer_gpu_, _FIELD_NAME)(f->type, L->sendBox, f, f->sendbuf_gpu_ptr);
        L = L->next;
        i++;
    }
#endif
#endif
}

_DECLARE(start_sendrecv_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    const size_t mpi_chunks_per_site = sizeof(_SITE_TYPE) / sizeof(_REAL);

#ifdef WITH_NEW_GEOMETRY
    if (_F_NAME(sendrecv_guard_, _FIELD_NAME) != NULL && _F_NAME(sendrecv_guard_, _FIELD_NAME) != (void *)f->comm_req) {
        lprintf("TEST", 0, "commtype = %d\n", f->comm_type);
        error(1, 1, __func__, "More simultaneous communication attempted. Exiting...\n");
    }
    _F_NAME(sendrecv_guard_, _FIELD_NAME) = (void *)f->comm_req;
#endif

    // CPU comms
    if (f->comm_type & CPU_COMM) {
        //Complete pending communications
        _F_NAME(complete_sendrecv_, _FIELD_NAME)(f);
        //Sync send buffers
        _F_NAME(sync_, _FIELD_NAME)(f);
        //IRecv
        _BUFFER_FOR(i) {
            _REAL *recv_buffer = (_REAL *)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
            /* Data Destination Parameters */
            int recv_proc = type->rbuf_from_proc[i];
            size_t number_of_sites = type->rbuf_len[i];
            size_t recv_size_in_dbl = (_FIELD_DIM)*number_of_sites * mpi_chunks_per_site;
            /* Communications */
            MPI_Irecv(recv_buffer, recv_size_in_dbl, _MPI_REAL, recv_proc, i, cart_comm, &(f->comm_req[2 * i + 1]));
        }
        //ISend
        _BUFFER_FOR(i) {
#ifndef WITH_NEW_GEOMETRY
            int master_shift = type->master_shift;
#else
            int master_shift = 0;
#endif
            _REAL *send_buffer = (_REAL *)(_DFIELD_AT_PTR(f->sendbuf_ptr, f->type->sbuf_start[i], 0, master_shift, _FIELD_DIM));
            /* Data Origin Parameters */
            int send_proc = type->sbuf_to_proc[i];
            size_t number_of_sites = type->sbuf_len[i];
            size_t send_size_in_dbl = (_FIELD_DIM)*number_of_sites * mpi_chunks_per_site;
            /* Communications */
            MPI_Isend(send_buffer, send_size_in_dbl, _MPI_REAL, send_proc, i, cart_comm, &(f->comm_req[2 * i]));
        }
    }
#ifdef WITH_GPU
    // GPU comms
    if (f->comm_type & GPU_COMM) {
        //Complete pending communications
        _F_NAME(complete_sendrecv_, _FIELD_NAME)(f);
        //Sync send buffers
        _GPU_F_NAME(sync_, _FIELD_NAME)(f);
        //IRecv
        _BUFFER_FOR(i) {
            _REAL *recv_buffer = (_REAL *)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));
            /* Data Destination Parameters */
            int recv_proc = type->rbuf_from_proc[i];
            size_t number_of_sites = roundUp(type->rbuf_len[i], THREADSIZE);
            size_t recv_size_in_dbl = (_FIELD_DIM)*number_of_sites * mpi_chunks_per_site;
            /* Communications */
            MPI_Irecv(recv_buffer, recv_size_in_dbl, _MPI_REAL, recv_proc, i, cart_comm, &(f->comm_req[2 * i + 1]));
        }
        //ISend
        _BUFFER_FOR(i) {
#ifndef WITH_NEW_GEOMETRY
            //            int master_shift = type->master_shift;
#else
            //            int master_shift = 0;
#endif
            //TODO: why no master shift in GPU ???
            _REAL *send_buffer = (_REAL *)(_DFIELD_AT_PTR(f->sendbuf_gpu_ptr, f->type->sbuf_start[i], 0, 0, _FIELD_DIM));
            /* Data Origin Parameters */
            int send_proc = type->sbuf_to_proc[i];
            size_t number_of_sites = roundUp(type->sbuf_len[i], THREADSIZE);
            size_t send_size_in_dbl = (_FIELD_DIM)*number_of_sites * mpi_chunks_per_site;
            /* Communications */
            MPI_Isend(send_buffer, send_size_in_dbl, _MPI_REAL, send_proc, i, cart_comm, &(f->comm_req[2 * i]));
        }
    }
#endif
#endif
}

_DECLARE(complete_sendrecv_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
    geometry_descriptor *type = f->type;
    int nreq = 2 * _NUMBER_OF_BUFFERS(type, _GEOM_TYPE);
#ifdef WITH_NEW_GEOMETRY
    _F_NAME(sendrecv_guard_, _FIELD_NAME) = NULL;
#endif
    if (nreq > 0) {
        MPI_Status status[nreq];
        MPI_Waitall(nreq, f->comm_req, status);
    }
#endif
}

///////////////////////////////////////
// These functions are for testing only
_DECLARE(fill_buffers_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
    const geometry_descriptor *type = f->type;
    const size_t chunks_per_site = sizeof(_SITE_TYPE) / sizeof(_REAL);
    if (f->comm_type & CPU_COMM) {
        _BUFFER_FOR(i) {
            size_t number_of_sites = type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM * number_of_sites * chunks_per_site;
            _REAL *buffer = (_REAL *)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
            _F_NAME(random_, _REAL)(buffer, buffer_length);
        }
    }
#ifdef WITH_GPU
    if (f->comm_type & GPU_COMM) {
        _BUFFER_FOR(i) {
            size_t number_of_sites = type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM * number_of_sites * chunks_per_site;
            _REAL *random_array = (_REAL *)malloc(buffer_length * sizeof(_REAL));
            _F_NAME(random_, _REAL)(random_array, buffer_length);
            _REAL *buffer = (_REAL *)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));
            cudaMemcpy(buffer, random_array, buffer_length * sizeof(_REAL), cudaMemcpyHostToDevice);
            free(random_array);
        }
    }
#endif
#endif
}

_DECLARE(fill_buffers_with_zeroes_, (_FIELD_TYPE * f)) {
#ifdef WITH_MPI
    const geometry_descriptor *type = f->type;
    const size_t chunks_per_site = sizeof(_SITE_TYPE) / sizeof(_REAL);
    if (f->comm_type & CPU_COMM) {
        _BUFFER_FOR(i) {
            size_t number_of_sites = type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM * number_of_sites * chunks_per_site;
            _REAL *buffer = (_REAL *)(_BUF_DFIELD_BLK(f, i, _FIELD_DIM));
            memset(buffer, 0, buffer_length * sizeof(_REAL));
        }
    }
#ifdef WITH_GPU
    if (f->comm_type & GPU_COMM) {
        _BUFFER_FOR(i) {
            size_t number_of_sites = type->rbuf_len[i];
            size_t buffer_length = _FIELD_DIM * number_of_sites * chunks_per_site;
            _REAL *buffer = (_REAL *)(_BUF_GPU_DFIELD_BLK(f, i, _FIELD_DIM));
            cudaMemset(buffer, 0, buffer_length * sizeof(_REAL));
        }
    }
#endif
#endif
}

#undef _DECLARE
#undef _GPU_DECLARE
#undef _FIELD_NAME
#undef _FIELD_TYPE
#undef _SITE_TYPE
#undef _FIELD_DIM
#undef _MPI_REAL
#undef _REAL
#undef round_up_buflen
