/***************************************************************************\
* Copyright (c) 2008, 2022, Claudio Pica, Sofie Martins                     *
* All rights reserved.                                                      *
\***************************************************************************/

/**
 * @file Dphi_gpu.c
 * @brief GPU implementation of the Wilson-Dirac operator D and its hermitian version
 *        on a given double-precision spinor field.
 */

#include "../Dphi_gpu_kernels.hpp"
#include "libhr_core.h"
#include "memory.h"
#include "inverters.h"
#include <string.h>
#include "Utils/generics.h"
#include <stdio.h>
#include <unistd.h>

#if !defined(_FIELD_TYPE)
#error Missing _FIELD_TYPE in Dphi_gpu.cu
#endif
#if !defined(_SPINOR_TYPE)
#error Missing _SPINOR_TYPE in Dphi_gpu.cu
#endif
#if !defined(_HSPINOR_TYPE)
#error Missing _HSPINOR_TYPE in Dphi_gpu.cu
#endif
#if !defined(_VECTOR_TYPE)
#error Missing _VECTOR_TYPE in Dphi_gpu.cu
#endif
#if !defined(_COMPLEX)
#error Missing _COMPLEX in Dphi_gpu.cu
#endif
#if !defined(_REAL)
#error Missing _REAL in Dphi_gpu.cu
#endif
#if !defined(_GAUGE_TYPE)
#error Missing _GAUGE_TYPE in Dphi_gpu.cu
#endif
#if !defined(_SUFFIX)
#error Missing _SUFFIX in Dphi_gpu.cu
#endif

#ifdef WITH_GPU

#define _CONCAT_(_name, _suffix) _name##_suffix##_
#define _F_NAME_(_name, _suffix) _CONCAT_(_name, _suffix)
#define _VAR(_name, _suffix) CONCAT(_name, _suffix)

#define _CONCAT_GPU_(_name, _suffix) _name##_suffix##_gpu_
#define _GPU_F_NAME_(_name, _suffix) _CONCAT_GPU_(_name, _suffix)

#define _FUNC_INNER(_type, _name, _suffix, _args) _type _GPU_F_NAME(_name, _suffix) _args
#define _DECLARE(_type, _name, _args) _FUNC_INNER(_type, _name, _SUFFIX, _args)
#define GFIELD(_gauge, _suffix) CONCAT(_gauge, _suffix)

#define _ALIAS_INNER(_type, _name, _suffix, _args) _type(*_F_NAME(_name, _suffix)) _args = _GPU_F_NAME(_name, _suffix)
#define _ALIAS_INNER_(_type, _name, _suffix, _args) _type(*_F_NAME_(_name, _suffix)) _args = _GPU_F_NAME_(_name, _suffix)

static int _VAR(init, _SUFFIX) = 1;
static int _VAR(bc_initialized, _SUFFIX) = 0;
static _FIELD_TYPE *_VAR(gtmp, _SUFFIX) = NULL;
static _FIELD_TYPE *_VAR(etmp, _SUFFIX) = NULL;
static _FIELD_TYPE *_VAR(otmp, _SUFFIX) = NULL;

#define max(a, b) (a > b ? a : b)

/**
 * @brief Initializes the boundary conditions for fermion twisting
 */
_DECLARE(static void, init_bc_, ()) {
#ifdef FERMION_THETA
    if (!_VAR(bc_initialized, _SUFFIX)) {
        cudaMemcpyToSymbol(eitheta_gpu, eitheta, 4 * sizeof(_COMPLEX), 0, cudaMemcpyHostToDevice);
        CudaCheckError();
        _VAR(bc_initialized, _SUFFIX) = 1;
    }
#endif
}

/**
 * @brief the following variable is used to keep trace of
 *        matrix-vector multiplication.
 *        we count how many time the function Dphi_ is called
 */
static unsigned long int _VAR(MVMcounter, _SUFFIX) = 0;

/**
 * @brief Getter for number of applications of the Dirac operator
 */
_DECLARE(unsigned long int, getMVM, ()) {
    unsigned long int res = _VAR(MVMcounter, _SUFFIX) >> 1; /* divide by two */
    return res;
}

/**
 * @brief Reset counter for number of applications of the Dirac operator
 */
_DECLARE(void, resetMVM, ()) {
    _VAR(MVMcounter, _SUFFIX) = 0;
}

/**
 * @brief Free fields allocated for intermediate storage of field data.
 */
_DECLARE(static void, free_mem, ()) {
    if (_VAR(gtmp, _SUFFIX) != NULL) {
        _F_NAME(free_, _FIELD_TYPE)(_VAR(gtmp, _SUFFIX));
        _VAR(etmp, _SUFFIX) = NULL;
    }
    if (_VAR(etmp, _SUFFIX) != NULL) {
        _F_NAME(free_, _FIELD_TYPE)(_VAR(etmp, _SUFFIX));
        _VAR(etmp, _SUFFIX) = NULL;
    }
    if (_VAR(otmp, _SUFFIX) != NULL) {
        _F_NAME(free_, _FIELD_TYPE)(_VAR(otmp, _SUFFIX));
        _VAR(otmp, _SUFFIX) = NULL;
    }
    _VAR(init, _SUFFIX) = 1;
}

/**
 * @brief Allocate fields intended for storage of field data in intermediate
 *        steps
 */
_DECLARE(static void, init_Dirac, ()) {
    if (_VAR(init, _SUFFIX)) {
        // Change standard communication and allocation mode
        // Since the tmp fields are only allocated on the GPU
        comm_t current_std_comm_t = std_comm_t;
        std_comm_t = GPU_COMM;
        alloc_mem_t = GPU_MEM;

        _VAR(gtmp, _SUFFIX) = _F_NAME(alloc_, _FIELD_TYPE)(1, &glattice);
        _VAR(etmp, _SUFFIX) = _F_NAME(alloc_, _FIELD_TYPE)(1, &glat_even);
        _VAR(otmp, _SUFFIX) = _F_NAME(alloc_, _FIELD_TYPE)(1, &glat_odd);

        // Reset standard communication and allocation mode
        alloc_mem_t = std_mem_t;
        std_comm_t = current_std_comm_t;
        atexit(&_GPU_F_NAME(free_mem, _SUFFIX));
        _VAR(init, _SUFFIX) = 0;
    }
}

/**
 * @brief Applies the Wilson-Dirac operator only where the calculation
 *        does not depend on the communications. Use this calculation
 *        to mask communication latency.
 *
 * @param in                  Input spinor field, defined on GPU copy
 * @param out                 Output spinor field to save result
 */
_DECLARE(static void, Dphi_inner, (_FIELD_TYPE * out, _FIELD_TYPE *in)) {
    const gd_type gd_t = in->type->desc;

#ifdef LARGE_N
    int grid = (max(boxEvenVolume(geometryBoxes) * NF, boxOddVolume(geometryBoxes) * NF) - 1) / BLOCK_SIZE_DIRAC + 1;
#else
    int grid = (max(boxEvenVolume(geometryBoxes), boxOddVolume(geometryBoxes)) - 1) / BLOCK_SIZE_DIRAC + 1;
#endif

    _SPINOR_TYPE *in_offset = in->gpu_ptr - in->type->master_shift;
    _SPINOR_TYPE *out_offset = out->gpu_ptr - out->type->master_shift;
    const _GAUGE_TYPE *gauge = GFIELD(u_gauge_f, _REP_SUFFIX)->gpu_ptr;

    if (gd_t & EVEN) {
        Dphi_gpu_inner_kernel<_HSPINOR_TYPE, _REAL, _COMPLEX, _SPINOR_TYPE, _GAUGE_TYPE>
            <<<grid, BLOCK_SIZE_DIRAC, 0, non_default_stream>>>(in_offset, out_offset, gauge, boxEvenVolume(geometryBoxes),
                                                                boxOddVolume(geometryBoxes), geometryBoxes->base_index,
                                                                geometryBoxes->base_index_odd, EVEN, imask_gpu, iup_gpu,
                                                                idn_gpu);
    }

    if (gd_t & ODD) {
        Dphi_gpu_inner_kernel<_HSPINOR_TYPE, _REAL, _COMPLEX, _SPINOR_TYPE, _GAUGE_TYPE>
            <<<grid, BLOCK_SIZE_DIRAC, 0, non_default_stream>>>(in_offset, out_offset, gauge, boxOddVolume(geometryBoxes),
                                                                boxEvenVolume(geometryBoxes), geometryBoxes->base_index_odd,
                                                                geometryBoxes->base_index, ODD, imask_gpu, iup_gpu, idn_gpu);
    }
    CudaCheckError();
}

/**
 * @brief Applies the Wilson-Dirac operator only where the calculation
 *        depends on the communications. Call this after having
 *        completed the spinor field communications.
 *
 * @param in                  Input spinor field defined on the extended
 *                            lattice on the GPU copy.
 * @param out                 Output spinor field to save result
 */
_DECLARE(static void, Dphi_boundary, (_FIELD_TYPE * out, _FIELD_TYPE *in)) {
    const gd_type gd_t = in->type->desc;
    box_t *buffer_box = geometryBoxes->next;
    int i = 1;
    int nbuffers = in->type->nbuffers_spinor;
    if (gd_t == GLOBAL) { nbuffers /= 2; }

    while (buffer_box && i <= nbuffers) {
        _SPINOR_TYPE *in_offset = in->gpu_ptr - in->type->master_shift;
        _SPINOR_TYPE *out_offset = out->gpu_ptr - out->type->master_shift;
        const _GAUGE_TYPE *gauge = GFIELD(u_gauge_f, _REP_SUFFIX)->gpu_ptr;

        int grid = (boxEvenVolume(geometryBoxes) - 1) / BLOCK_SIZE + 1;

        if (gd_t & EVEN) {
            Dphi_gpu_boundary_kernel<_HSPINOR_TYPE, _REAL, _SPINOR_TYPE, _GAUGE_TYPE><<<grid, BLOCK_SIZE>>>(
                in_offset, out_offset, gauge, boxEvenVolume(buffer_box), boxOddVolume(geometryBoxes), buffer_box->base_index,
                geometryBoxes->base_index_odd, EVEN, buffer_box->mask, iup_gpu, idn_gpu);
        }

        if (gd_t & ODD) {
            Dphi_gpu_boundary_kernel<_HSPINOR_TYPE, _REAL, _SPINOR_TYPE, _GAUGE_TYPE><<<grid, BLOCK_SIZE>>>(
                in_offset, out_offset, gauge, boxOddVolume(buffer_box), boxEvenVolume(geometryBoxes),
                buffer_box->base_index_odd, geometryBoxes->base_index, ODD, buffer_box->mask, iup_gpu, idn_gpu);
        }
        CudaCheckError();

        buffer_box = buffer_box->next;
        i++;
    }
}

/**
 * @brief Implementation of the massless Wilson-Dirac operator on the GPU
 *
 * @param in                      Input spinor field
 * @param out                     Output spinor field to save result
 */
void _GPU_F_NAME_(Dphi, _SUFFIX)(_FIELD_TYPE *out, _FIELD_TYPE *in) {
    _CHECK_GEOMETRY_EO(in, out);
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }
    _F_NAME(sync_reduced_init_, _FIELD_TYPE)(in);
#ifdef WITH_MPI
    _F_NAME(start_sendrecv_reduced_, _FIELD_TYPE)(in);
#endif
    _GPU_F_NAME(Dphi_inner, _SUFFIX)(out, in);
#ifdef WITH_MPI
    _F_NAME(complete_sendrecv_reduced_, _FIELD_TYPE)(in);
    _GPU_F_NAME(Dphi_boundary, _SUFFIX)(out, in);
#endif
}

#ifdef WITH_CLOVER
void _GPU_F_NAME_(Cphi, _SUFFIX)(double mass, _FIELD_TYPE *dptr, _FIELD_TYPE *sptr, int assign) {
    mass = (4. + mass);
    _PIECE_FOR(sptr->type, ixp) {
        const int N = sptr->type->master_end[ixp] - sptr->type->master_start[ixp] + 1;
        const int grid = (N * NF * 4 - 1) / BLOCK_SIZE_CLOVER + 1;
        const int block_start = sptr->type->master_start[ixp];
        suNfc *cl_term_gpu = cl_term->gpu_ptr + 4 * block_start;
        Cphi_gpu_kernel_<_VECTOR_TYPE, _REAL, _COMPLEX><<<grid, BLOCK_SIZE_CLOVER, 0, 0>>>(
            _GPU_FIELD_BLK(dptr, ixp), _GPU_FIELD_BLK(sptr, ixp), cl_term_gpu, mass, assign, N, block_start);
    }
}

void _GPU_F_NAME_(Cphi_inv, _SUFFIX)(double mass, _FIELD_TYPE *dptr, _FIELD_TYPE *sptr, int assign) {
    mass = (4. + mass);
    compute_ldl_decomp(mass);

    _F_NAME(start_sendrecv_, _FIELD_TYPE)(sptr);
    _F_NAME(complete_sendrecv_, _FIELD_TYPE)(sptr);

    start_sendrecv_ldl_field(cl_ldl);
    complete_sendrecv_ldl_field(cl_ldl);

    _PIECE_FOR(sptr->type, ixp) {
        const int N = sptr->type->master_end[ixp] - sptr->type->master_start[ixp] + 1;
        const int grid = (N - 1) / BLOCK_SIZE_CLOVER + 1;
        const int block_start = sptr->type->master_start[ixp];
        ldl_t *cl_ldl_gpu = cl_ldl->gpu_ptr + block_start;
        Cphi_inv_kernel_<_VECTOR_TYPE, _COMPLEX, _REAL><<<grid, BLOCK_SIZE_CLOVER, 0, 0>>>(
            _GPU_FIELD_BLK(dptr, ixp), _GPU_FIELD_BLK(sptr, ixp), cl_ldl_gpu, mass, assign, N, block_start);
    }
}
#endif

#ifdef WITH_EXPCLOVER
void _GPU_F_NAME_(Cphi, _SUFFIX)(double mass, _FIELD_TYPE *dptr, _FIELD_TYPE *sptr, int assign, int inverse) {
    evaluate_sw_order(&mass);

    mass = (4. + mass);
    double invexpmass = 1.0 / mass;
    if (inverse == 1) {
        invexpmass = -1.0 / mass;
        mass = 1 / mass;
    }

    int NN_loc = get_NN();
    int NNexp_loc = get_NNexp();

    _PIECE_FOR(sptr->type, ixp) {
        const int N = sptr->type->master_end[ixp] - sptr->type->master_start[ixp] + 1;
        const int grid = (N * NF * 4 - 1) / BLOCK_SIZE_CLOVER + 1;
        const int block_start = sptr->type->master_start[ixp];
        suNfc *cl_term_gpu = cl_term->gpu_ptr + 4 * block_start;
        Cphi_gpu_kernel_<_VECTOR_TYPE, _REAL>
            <<<grid, BLOCK_SIZE_CLOVER, 0, 0>>>(_GPU_FIELD_BLK(dptr, ixp), _GPU_FIELD_BLK(sptr, ixp), cl_term_gpu, mass,
                                                invexpmass, assign, N, block_start, NN_loc, NNexp_loc);
    }
}
#endif

/**
 * @brief Implementation of the Wilson-Dirac operator with mass on the GPU.
 *
 * @param in                    Input spinor field defined on the full lattice
 * @param out                   Output spinor field defined on the full lattice that is 
 *                              the result of the application of the Wilson-Dirac operator 
 *                              on the input spinor field.
 * @param m0                    Mass parameter
 */
_DECLARE(void, Dphi, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    //Input argument validity checks
    _CHECK_GEOMETRY_FULL(in);
    _CHECK_GEOMETRY_FULL(out);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(in);

    // Operation
    double rho = 4. + m0;
    _GPU_F_NAME_(Dphi, _SUFFIX)(out, in);

    //mul_add_assign(out, (_REAL)rho, in);
    _F_NAME(mul_add_assign_spinor_field, _REP_SUFFIX)(out, rho, in);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(out);
}

/**
 * @brief Implementation of the Hermitian Wilson-Dirac operator with mass on the GPU.
 *
 * @param in                    Input spinor field defined on the full lattice
 * @param out                   Output spinor field defined on the full lattice that is 
 *                              the result of the application of the Hermitian Wilson-Dirac 
 *                              operator on the input spinor field
 * @param m0                    Mass parameter
 */
_DECLARE(void, g5Dphi, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // Input argument validity checks
    _CHECK_GEOMETRY_FULL(in);
    _CHECK_GEOMETRY_FULL(out);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(in);

    // Operation
    double rho = 4. + m0;
    _GPU_F_NAME_(Dphi, _SUFFIX)(out, in);
    _F_NAME(mul_add_assign_spinor_field, _REP_SUFFIX)(out, rho, in);
    _F_NAME(g5_assign_spinor_field, _REP_SUFFIX)(out);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(out);
}

/**
  * @brief Even-odd preconditioned Wilson-Dirac operator with mass on the GPU.
  *
  * @param in                 Even input spinor field
  * @param out                Even output spinor field that is the result of the application
  *                           of the even-odd preconditioned Wilson-Dirac operator on the 
  *                           input spinor field
  * @param m0                 Mass parameter
  */
_DECLARE(void, Dphi_eopre, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // Input argument validity checks
    _CHECK_GEOMETRY_EVEN(in);
    _CHECK_GEOMETRY_EVEN(out);

    // alloc memory for temporary spinor field
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(in);

    // Operation
    _GPU_F_NAME_(Dphi, _SUFFIX)(_VAR(otmp, _SUFFIX), in);
    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(_VAR(otmp, _SUFFIX));
    _GPU_F_NAME_(Dphi, _SUFFIX)(out, _VAR(otmp, _SUFFIX));
    double rho = 4. + m0;
    rho *= -rho; /* this minus sign is taken into account below */
    _F_NAME(mul_add_assign_spinor_field, _REP_SUFFIX)(out, rho, in);
    _F_NAME(minus_spinor_field, _REP_SUFFIX)(out, out);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(out);
}

/**
  * @brief Even-odd preconditioned Wilson-Dirac operator with mass on the GPU.
  *
  * @param in                 Odd input spinor field
  * @param out                Odd output spinor field that is the result of the application
  *                           of the even-odd preconditioned Wilson-Dirac operator on the 
  *                           input spinor field
  * @param m0                 Mass parameter
  */
_DECLARE(void, Dphi_oepre, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // Input argument validity checks
    _CHECK_GEOMETRY_ODD(in);
    _CHECK_GEOMETRY_ODD(out);

    // alloc memory for temporary spinor field
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(in);

    _GPU_F_NAME_(Dphi, _SUFFIX)(_VAR(etmp, _SUFFIX), in);
    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(_VAR(etmp, _SUFFIX));
    _GPU_F_NAME_(Dphi, _SUFFIX)(out, _VAR(etmp, _SUFFIX));
    double rho = 4. + m0;
    rho *= -rho; /* this minus sign is taken into account below */
    _F_NAME(mul_add_assign_spinor_field, _REP_SUFFIX)(out, rho, in);
    _F_NAME(minus_spinor_field, _REP_SUFFIX)(out, out);

    _F_NAME(apply_BCs_on_, _FIELD_TYPE)(out);
}

/**
  * @brief Even-odd preconditioned Hermitian Wilson-Dirac operator with mass on the GPU.
  *
  * @param in                 Even input spinor field
  * @param out                Even output spinor field that is the result of the application
  *                           of the even-odd preconditioned Wilson-Dirac operator on the 
  *                           input spinor field
  * @param m0                 Mass parameter
  */
_DECLARE(void, g5Dphi_eopre, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // Input argument validity checks
    _CHECK_GEOMETRY_EVEN(in);
    _CHECK_GEOMETRY_EVEN(out);

#if defined(BC_T_SF) || defined(BC_T_SF_ROTATED)
    _CALL(SF_spinor_bcs)(in);
#endif

    // alloc memory for temporary spinor field
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }

    // Operation
    _GPU_F_NAME_(Dphi, _SUFFIX)(_VAR(otmp, _SUFFIX), in);
    _GPU_F_NAME_(Dphi, _SUFFIX)(out, _VAR(otmp, _SUFFIX));
    double rho = 4. + m0;
    rho *= -rho; /* this minus sign is taken into account below */
    _F_NAME(mul_add_assign_spinor_field, _REP_SUFFIX)(out, rho, in);
    _F_NAME(minus_spinor_field, _REP_SUFFIX)(out, out);
    _F_NAME(g5_assign_spinor_field, _REP_SUFFIX)(out);

#if defined(BC_T_SF) || defined(BC_T_SF_ROTATED)
    _F_NAME(SF_spinor_bcs)(out);
#endif
}

/**
  * @brief Even-odd preconditioned squared Hermitian Wilson-Dirac operator with mass on the GPU.
  *
  * @param in                 Even input spinor field
  * @param out                Even output spinor field that is the result of the application
  *                           of the even-odd preconditioned Wilson-Dirac operator on the 
  *                           input spinor field
  * @param m0                 Mass parameter
  */
_DECLARE(void, g5Dphi_eopre_sq, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // alloc memory for temporary spinor field
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }

    _GPU_F_NAME(g5Dphi_eopre, _SUFFIX)(m0, _VAR(etmp, _SUFFIX), in);
    _GPU_F_NAME(g5Dphi_eopre, _SUFFIX)(m0, out, _VAR(etmp, _SUFFIX));
}

/**
 * @brief Implementation of the squared Hermitian Wilson-Dirac operator with mass on the GPU.
 *
 * @param in                    Input spinor field defined on the full lattice
 * @param out                   Output spinor field defined on the full lattice that is 
 *                              the result of the application of the Hermitian Wilson-Dirac 
 *                              operator on the input spinor field
 * @param m0                    Mass parameter
 */
_DECLARE(void, g5Dphi_sq, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in)) {
    // alloc memory for temporary spinor field
    if (_VAR(init, _SUFFIX)) { _GPU_F_NAME(init_Dirac, _SUFFIX)(); }

    _GPU_F_NAME(g5Dphi, _SUFFIX)(m0, _VAR(gtmp, _SUFFIX), in);
    _GPU_F_NAME(g5Dphi, _SUFFIX)(m0, out, _VAR(gtmp, _SUFFIX));
}

_ALIAS_INNER(unsigned long int, getMVM, _SUFFIX, ());
_ALIAS_INNER_(void, Dphi, _SUFFIX, (_FIELD_TYPE * out, _FIELD_TYPE *in));
_ALIAS_INNER(void, Dphi, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, g5Dphi, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, g5Dphi_sq, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, Dphi_eopre, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, Dphi_oepre, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, g5Dphi_eopre, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));
_ALIAS_INNER(void, g5Dphi_eopre_sq, _SUFFIX, (double m0, _FIELD_TYPE *out, _FIELD_TYPE *in));

#ifdef WITH_CLOVER
_ALIAS_INNER_(void, Cphi, _SUFFIX, (double mass, _FIELD_TYPE *, _FIELD_TYPE *, int));
_ALIAS_INNER_(void, Cphi_inv, _SUFFIX, (double mass, _FIELD_TYPE *, _FIELD_TYPE *, int));
#endif
#ifdef WITH_EXPCLOVER
_ALIAS_INNER_(void, Cphi, _SUFFIX, (double mass, _FIELD_TYPE *, _FIELD_TYPE *, int, int));
#endif

#undef _FIELD_TYPE
#undef _SPINOR_TYPE
#undef _HSPINOR_TYPE
#undef _VECTOR_TYPE
#undef _COMPLEX
#undef _GAUGE_TYPE
#undef _SUFFIX
#undef _REP_SUFFIX
#undef _REAL
#undef _SUNFC

#undef _VAR
#undef _GPU_F_NAME_
#undef _FUNC_INNER
#undef _CALL
#undef DPHI_MASSLESS
#undef _DECLARE

#endif
