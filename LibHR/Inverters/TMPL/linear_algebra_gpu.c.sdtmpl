/***************************************************************************\
* Copyright (c) 2008,2011, Claudio Pica, Ari Hietanen and Ulrik SÃ¸ndergaard *
* All rights reserved.                                                      *
\***************************************************************************/

#include "communications.h"
#include "gpu.h"
#include <stdio.h>

#define _TOCOMPLEX(sp) ((_COMPLEX *)(sp))
#define _NCOM (sizeof(_SPINOR_TYPE)/sizeof(_COMPLEX))

#define _CUDA_FOR(s,ixp,body)       								\
  do {												\
    _PIECE_FOR((s)->type, (ixp)){   								\
       unsigned int N = (s)->type->master_end[(ixp)] - (s)->type->master_start[(ixp)] + 1;  	\
       N *= _NCOM;  										\
       unsigned int grid_size = (N-1)/BLOCK_SIZE + 1;  						\
       body; 											\
       CudaCheckError(); 									\
    }												\
  } while(0)

#include "linear_algebra_gpu.cu"

void _FUNC(spinor_field_copy)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  cudaMemcpy(s1->gpu_ptr,s2->gpu_ptr,s1->type->gsize_spinor*sizeof(_SPINOR_TYPE),cudaMemcpyDeviceToDevice);
}

/* Re <s1,s2> */
double _FUNC(spinor_field_prod_re)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  double res = 0.0;
  double *resPiece;

  _CUDA_FOR(s1,ixp,
            resPiece = alloc_double_sum_field(N);
            (spinor_field_prod_re_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),resPiece,N));
            res += global_sum_gpu(resPiece,N);
  );
  return res;
}

/* Im <s1,s2> */
double _FUNC(spinor_field_prod_im)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  double res = 0.0;
  double *resPiece;

  _CUDA_FOR(s1,ixp,
            resPiece = alloc_double_sum_field(N);
            (spinor_field_prod_im_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),resPiece,N));
            res += global_sum_gpu(resPiece,N);
  );
  return res;
}

/* <s1,s2> */
hr_complex _FUNC(spinor_field_prod)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  hr_complex res = 0.0;
  hr_complex *resPiece;

  _CUDA_FOR(s1,ixp,
            resPiece = alloc_complex_sum_field(N);
            (spinor_field_prod_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),resPiece,N));
            res += global_sum_gpu(resPiece,N);
  );
  return res;
}

/* Re <g5*s1,s2> */
double _FUNC(spinor_field_g5_prod_re)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  double res = 0.0;
  double *resPiece;

  _PIECE_FOR(s1->type, ixp){
      unsigned int N = s1->type->master_end[ixp] - s1->type->master_start[ixp] + 1;
      N *= _NCOM;
      unsigned int grid_size = ((N-1)/BLOCK_SIZE + 1)/2;
      resPiece = alloc_double_sum_field(N);
      spinor_field_prod_re_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),resPiece,N/2);
      spinor_field_g5_prod_re_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp))+N/2,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp))+N/2,resPiece+N/2,N/2);
      res += global_sum_gpu(resPiece,N);
      CudaCheckError();
  }
  return res;
}

/* Im <g5*s1,s2> */
double _FUNC(spinor_field_g5_prod_im)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  double res = 0.0;
  double *resPiece;

  _PIECE_FOR(s1->type, ixp){
      unsigned int N = s1->type->master_end[ixp] - s1->type->master_start[ixp] + 1;
      N *= _NCOM;
      unsigned int grid_size = ((N-1)/BLOCK_SIZE + 1)/2;
      resPiece = alloc_double_sum_field(N);
      spinor_field_prod_im_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),resPiece,N/2);
      spinor_field_g5_prod_im_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp))+N/2,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp))+N/2,resPiece+N/2,N/2);
      res += global_sum_gpu(resPiece,N);
      CudaCheckError();
  }
  return res;
}

/* Re <s1,s1> */
double _FUNC(spinor_field_sqnorm)(_SPINOR_FIELD_TYPE *s1)
{
  double res = 0.0;
  double *resPiece;

  _CUDA_FOR(s1,ixp,
            resPiece = alloc_double_sum_field(N);
            (spinor_field_sqnorm_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),resPiece,N));
            res += global_sum_gpu(resPiece,N);
  );
  return res;
}

/* s1+=r*s2 r real */
void _FUNC(spinor_field_mul_add_assign)(_SPINOR_FIELD_TYPE *s1, _REAL r, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_mul_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),r,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N))
  );
}

/* s1+=c*s2 c complex */
void _FUNC(spinor_field_mulc_add_assign)(_SPINOR_FIELD_TYPE *s1, _COMPLEX c, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_mulc_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),c,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N))
  );
}

/* s1=r*s2 */
void _FUNC(spinor_field_mul)(_SPINOR_FIELD_TYPE *s1, _REAL r, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_mul_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),r,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N))
  );
}

/* s1=c*s2 c complex */
void _FUNC(spinor_field_mulc)(_SPINOR_FIELD_TYPE *s1, _COMPLEX c, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_mulc_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),c,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N))
  );
}

/* r=s1+s2 */
void _FUNC(spinor_field_add)(_SPINOR_FIELD_TYPE *r, _SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_add_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(r,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

/* r=s1-s2 */
void _FUNC(spinor_field_sub)(_SPINOR_FIELD_TYPE *r, _SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_sub_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(r,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

/* s1+=s2 */
void _FUNC(spinor_field_add_assign)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

/* s1-=s2 */
void _FUNC(spinor_field_sub_assign)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_sub_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

/* s1=0 */
void _FUNC(spinor_field_zero)(_SPINOR_FIELD_TYPE *s1)
{
  _CUDA_FOR(s1,ixp,
            (spinor_field_zero_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),N));
  );
}

/* s1=-s2 */
void _FUNC(spinor_field_minus)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_minus_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

/* s1=r1*s2+r2*s3 */
void _FUNC(spinor_field_lc)(_SPINOR_FIELD_TYPE *s1, _REAL r1, _SPINOR_FIELD_TYPE *s2, _REAL r2, _SPINOR_FIELD_TYPE *s3)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _TWO_SPINORS_MATCHING(s1,s3);
  _CUDA_FOR(s1,ixp,
            (spinor_field_lc_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),r1,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),r2,_TOCOMPLEX(_GPU_FIELD_BLK(s3,ixp)),N));
  );
}

/* s1+=r1*s2+r2*s3 */
void _FUNC(spinor_field_lc_add_assign)(_SPINOR_FIELD_TYPE *s1, _REAL r1, _SPINOR_FIELD_TYPE *s2, _REAL r2, _SPINOR_FIELD_TYPE *s3)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _TWO_SPINORS_MATCHING(s1,s3);
  _CUDA_FOR(s1,ixp,
            (spinor_field_lc_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),r1,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),r2,_TOCOMPLEX(_GPU_FIELD_BLK(s3,ixp)),N));
  );
}

/* s1=c1*s2+c2*s3 c1, c2 complex*/
void _FUNC(spinor_field_clc)(_SPINOR_FIELD_TYPE *s1, _COMPLEX c1, _SPINOR_FIELD_TYPE *s2, _COMPLEX c2, _SPINOR_FIELD_TYPE *s3)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _TWO_SPINORS_MATCHING(s1,s3);
  _CUDA_FOR(s1,ixp,
            (spinor_field_clc_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),c1,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),c2,_TOCOMPLEX(_GPU_FIELD_BLK(s3,ixp)),N));
  );
}

/* s1+=c1*s2+c2*s3 c1, c2 complex*/
void _FUNC(spinor_field_clc_add_assign)(_SPINOR_FIELD_TYPE *s1, _COMPLEX c1, _SPINOR_FIELD_TYPE *s2, _COMPLEX c2, _SPINOR_FIELD_TYPE *s3)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _TWO_SPINORS_MATCHING(s1,s3);
  _CUDA_FOR(s1,ixp,
            (spinor_field_clc_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),c1,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),c2,_TOCOMPLEX(_GPU_FIELD_BLK(s3,ixp)),N));
  );
}


/* s1=g5*s2  */
void _FUNC(spinor_field_g5)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
   _TWO_SPINORS_MATCHING(s1,s2);
   _PIECE_FOR(s1->type, ixp){
      unsigned int N = s1->type->master_end[ixp] - s1->type->master_start[ixp] + 1;
      N *= _NCOM;
      unsigned int grid_size = ((N-1)/BLOCK_SIZE + 1)/2;
      cudaMemcpy((_COMPLEX *) (_GPU_FIELD_BLK(s1,ixp)),(_COMPLEX *) (_GPU_FIELD_BLK(s2,ixp)),N/2*sizeof(_COMPLEX),cudaMemcpyDeviceToDevice);
      (spinor_field_minus_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp))+N/2,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp))+N/2,N/2));
      CudaCheckError();
   }
}

/* s1=g5*s1  */
void _FUNC(spinor_field_g5_assign)(_SPINOR_FIELD_TYPE *s1)
{
   _PIECE_FOR(s1->type, ixp){
      unsigned int N = s1->type->master_end[ixp] - s1->type->master_start[ixp] + 1;
      N *= _NCOM;
      unsigned int grid_size = ((N-1)/BLOCK_SIZE + 1)/2;
      (spinor_field_minus_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp))+N/2,N/2));
      CudaCheckError();
   }
}

/* s1+=c*g5*s2 c complex */
void _FUNC(spinor_field_g5_mulc_add_assign)(_SPINOR_FIELD_TYPE *s1, _COMPLEX c, _SPINOR_FIELD_TYPE *s2)
{
   _TWO_SPINORS_MATCHING(s1,s2);
   _PIECE_FOR(s1->type, ixp){
      unsigned int N = s1->type->master_end[ixp] - s1->type->master_start[ixp] + 1;
      N *= _NCOM;
      unsigned int grid_size = ((N-1)/BLOCK_SIZE + 1)/2;
      (spinor_field_mulc_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),c,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N/2));
      (spinor_field_g5_mulc_add_assign_gpu<<<grid_size,BLOCK_SIZE>>>(_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp))+N/2,c,_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp))+N/2,N/2));
      CudaCheckError();
   }

}

/* tools per eva.c  */
void _FUNC(spinor_field_lc1)(_REAL c1, _SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_lc1_gpu<<<grid_size,BLOCK_SIZE>>>(c1,_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

void _FUNC(spinor_field_lc2)(_REAL c1, _REAL c2, _SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_lc2_gpu<<<grid_size,BLOCK_SIZE>>>(c1,c2,_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),N));
  );
}

void _FUNC(spinor_field_lc3)(_REAL c1, _REAL c2, _SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2, _SPINOR_FIELD_TYPE *s3)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  /* c1=-c1; c2=-c2; */
  _REAL cc1=-c1;
  _REAL cc2=-c2;
  _CUDA_FOR(s1,ixp,
            (spinor_field_lc3_gpu<<<grid_size,BLOCK_SIZE>>>(cc1,cc2,_TOCOMPLEX(_GPU_FIELD_BLK(s1,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s2,ixp)),_TOCOMPLEX(_GPU_FIELD_BLK(s3,ixp)),N));
  );
}

void _FUNC(spinor_field_copy_gpu_to_gpu)(_SPINOR_FIELD_TYPE *s1, _SPINOR_FIELD_TYPE *s2)
{
  _TWO_SPINORS_MATCHING(s1,s2);
  _CUDA_FOR(s1,ixp,
            (spinor_field_copy_gpu_to_gpu_gpu<<<grid_size,BLOCK_SIZE>>>(((_COMPLEX*) _GPU_FIELD_BLK(s1,ixp)),((_COMPLEX*) _GPU_FIELD_BLK(s2,ixp)),N));
  );
}


#undef _TOCOMPLEX
#undef _NCOM
